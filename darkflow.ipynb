{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "darkflow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "sYA6iXr6eJ9G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "e659e7c2-6552-4636-c1de-ce1647101a2d"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LW2HrMlqKju2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! apt-get update\n",
        "! pip3 install numpy\n",
        "! apt-get install python-opencv -y\n",
        "! pip install cython"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9pr5uYY9SEx_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "986c3463-f244-4f89-e2b9-120d85d858bf"
      },
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My\\ Drive/Colab\\ Notebooks/YOLO-darkflow/darkflow\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/YOLO-darkflow/darkflow\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BWpY6LS6K7Hb",
        "colab_type": "code",
        "outputId": "0c3c73df-ff8c-467c-9d76-8da24ec23051",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -e ."
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/drive/My%20Drive/Colab%20Notebooks/YOLO-darkflow/darkflow\n",
            "Installing collected packages: darkflow\n",
            "  Running setup.py develop for darkflow\n",
            "Successfully installed darkflow\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aUL4fXv93Zlc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "from darkflow.net.build import TFNet\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%config InlineBackend.figure_format = 'svg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gx0XH72jMkwY",
        "colab_type": "code",
        "outputId": "fa70b78d-d52a-4e5e-e73f-da94c35a5921",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11928
        }
      },
      "cell_type": "code",
      "source": [
        "!flow --model \"cfg/tiny-yolo-voc-1c.cfg\" --load -1 --train --annotation train/annotations --dataset train/images --gpu 1.0 --epoch 300"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Parsing cfg/tiny-yolo-voc-1c.cfg\n",
            "Loading None ...\n",
            "Finished in 0.00013303756713867188s\n",
            "\n",
            "Building net ...\n",
            "Source | Train? | Layer description                | Output size\n",
            "-------+--------+----------------------------------+---------------\n",
            "       |        | input                            | (?, 416, 416, 3)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 416, 416, 16)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 208, 208, 16)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 208, 208, 32)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 104, 104, 32)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 104, 104, 64)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 52, 52, 64)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 52, 52, 128)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 26, 26, 128)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 256)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 13, 13, 256)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 512)\n",
            " Load  |  Yep!  | maxp 2x2p0_1                     | (?, 13, 13, 512)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 1x1p0_1    linear           | (?, 13, 13, 30)\n",
            "-------+--------+----------------------------------+---------------\n",
            "GPU mode with 1.0 usage\n",
            "cfg/tiny-yolo-voc-1c.cfg loss hyper-parameters:\n",
            "\tH       = 13\n",
            "\tW       = 13\n",
            "\tbox     = 5\n",
            "\tclasses = 1\n",
            "\tscales  = [1.0, 5.0, 1.0, 1.0]\n",
            "Building cfg/tiny-yolo-voc-1c.cfg loss\n",
            "Building cfg/tiny-yolo-voc-1c.cfg train op\n",
            "2019-01-04 05:23:54.045317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-01-04 05:23:54.045776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2019-01-04 05:23:54.045833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2019-01-04 05:23:55.025406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-01-04 05:23:55.025465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2019-01-04 05:23:55.025505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2019-01-04 05:23:55.025773: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-01-04 05:23:55.025872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11441 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "Loading from ./ckpt/tiny-yolo-voc-1c-250\n",
            "Finished in 9.731485605239868s\n",
            "\n",
            "Enter training ...\n",
            "\n",
            "cfg/tiny-yolo-voc-1c.cfg parsing train/annotations\n",
            "Parsing for ['grain'] \n",
            "[====================>]100%  DSCF3522.xml\n",
            "Statistics:\n",
            "grain: 215\n",
            "Dataset size: 89\n",
            "Dataset of 89 instance(s)\n",
            "Training statistics: \n",
            "\tLearning rate : 1e-05\n",
            "\tBatch size    : 16\n",
            "\tEpoch number  : 300\n",
            "\tBackup every  : 2000\n",
            "step 251 - loss 22.437868118286133 - moving ave loss 22.437868118286133\n",
            "step 252 - loss 21.39234161376953 - moving ave loss 22.333315467834474\n",
            "step 253 - loss 22.081912994384766 - moving ave loss 22.308175220489503\n",
            "step 254 - loss 21.661380767822266 - moving ave loss 22.24349577522278\n",
            "step 255 - loss 22.155866622924805 - moving ave loss 22.23473285999298\n",
            "Finish 1 epoch(es)\n",
            "step 256 - loss 21.823062896728516 - moving ave loss 22.193565863666535\n",
            "step 257 - loss 20.895343780517578 - moving ave loss 22.06374365535164\n",
            "step 258 - loss 22.02300453186035 - moving ave loss 22.05966974300251\n",
            "step 259 - loss 22.601573944091797 - moving ave loss 22.11386016311144\n",
            "step 260 - loss 20.376243591308594 - moving ave loss 21.940098505931157\n",
            "Finish 2 epoch(es)\n",
            "step 261 - loss 20.28990936279297 - moving ave loss 21.775079591617338\n",
            "step 262 - loss 20.796764373779297 - moving ave loss 21.677248069833535\n",
            "step 263 - loss 21.37493133544922 - moving ave loss 21.647016396395102\n",
            "step 264 - loss 20.806978225708008 - moving ave loss 21.563012579326394\n",
            "step 265 - loss 20.80404281616211 - moving ave loss 21.487115603009965\n",
            "Finish 3 epoch(es)\n",
            "step 266 - loss 19.158695220947266 - moving ave loss 21.254273564803697\n",
            "step 267 - loss 21.058216094970703 - moving ave loss 21.234667817820398\n",
            "step 268 - loss 20.615238189697266 - moving ave loss 21.172724855008084\n",
            "step 269 - loss 19.826452255249023 - moving ave loss 21.038097595032177\n",
            "step 270 - loss 20.776456832885742 - moving ave loss 21.011933518817532\n",
            "Finish 4 epoch(es)\n",
            "step 271 - loss 20.010276794433594 - moving ave loss 20.91176784637914\n",
            "step 272 - loss 20.93057632446289 - moving ave loss 20.913648694187515\n",
            "step 273 - loss 20.00066375732422 - moving ave loss 20.822350200501187\n",
            "step 274 - loss 18.108108520507812 - moving ave loss 20.550926032501852\n",
            "step 275 - loss 19.20241928100586 - moving ave loss 20.416075357352256\n",
            "Finish 5 epoch(es)\n",
            "step 276 - loss 18.7694091796875 - moving ave loss 20.25140873958578\n",
            "step 277 - loss 18.70783233642578 - moving ave loss 20.09705109926978\n",
            "step 278 - loss 18.705978393554688 - moving ave loss 19.957943828698273\n",
            "step 279 - loss 18.605634689331055 - moving ave loss 19.82271291476155\n",
            "step 280 - loss 19.490219116210938 - moving ave loss 19.78946353490649\n",
            "Finish 6 epoch(es)\n",
            "step 281 - loss 18.507633209228516 - moving ave loss 19.66128050233869\n",
            "step 282 - loss 17.93877410888672 - moving ave loss 19.489029862993494\n",
            "step 283 - loss 18.891204833984375 - moving ave loss 19.42924736009258\n",
            "step 284 - loss 18.830406188964844 - moving ave loss 19.36936324297981\n",
            "step 285 - loss 17.897991180419922 - moving ave loss 19.222226036723818\n",
            "Finish 7 epoch(es)\n",
            "step 286 - loss 17.775348663330078 - moving ave loss 19.077538299384443\n",
            "step 287 - loss 18.82791519165039 - moving ave loss 19.05257598861104\n",
            "step 288 - loss 18.224380493164062 - moving ave loss 18.969756439066344\n",
            "step 289 - loss 18.26787757873535 - moving ave loss 18.899568553033248\n",
            "step 290 - loss 18.15233612060547 - moving ave loss 18.82484530979047\n",
            "Finish 8 epoch(es)\n",
            "step 291 - loss 17.693561553955078 - moving ave loss 18.71171693420693\n",
            "step 292 - loss 18.352092742919922 - moving ave loss 18.67575451507823\n",
            "step 293 - loss 17.199390411376953 - moving ave loss 18.528118104708103\n",
            "step 294 - loss 17.38370132446289 - moving ave loss 18.41367642668358\n",
            "step 295 - loss 16.948495864868164 - moving ave loss 18.26715837050204\n",
            "Finish 9 epoch(es)\n",
            "step 296 - loss 17.58224868774414 - moving ave loss 18.19866740222625\n",
            "step 297 - loss 16.360551834106445 - moving ave loss 18.014855845414267\n",
            "step 298 - loss 16.637697219848633 - moving ave loss 17.877139982857706\n",
            "step 299 - loss 16.652402877807617 - moving ave loss 17.754666272352697\n",
            "step 300 - loss 17.03375244140625 - moving ave loss 17.682574889258053\n",
            "Finish 10 epoch(es)\n",
            "step 301 - loss 16.19585609436035 - moving ave loss 17.533903009768284\n",
            "step 302 - loss 16.215965270996094 - moving ave loss 17.402109235891064\n",
            "step 303 - loss 15.85051155090332 - moving ave loss 17.24694946739229\n",
            "step 304 - loss 15.374088287353516 - moving ave loss 17.059663349388416\n",
            "step 305 - loss 16.65667152404785 - moving ave loss 17.01936416685436\n",
            "Finish 11 epoch(es)\n",
            "step 306 - loss 17.197038650512695 - moving ave loss 17.037131615220193\n",
            "step 307 - loss 15.580329895019531 - moving ave loss 16.891451443200125\n",
            "step 308 - loss 15.855596542358398 - moving ave loss 16.787865953115954\n",
            "step 309 - loss 15.709744453430176 - moving ave loss 16.680053803147377\n",
            "step 310 - loss 15.251579284667969 - moving ave loss 16.53720635129944\n",
            "Finish 12 epoch(es)\n",
            "step 311 - loss 15.389938354492188 - moving ave loss 16.422479551618714\n",
            "step 312 - loss 15.738371849060059 - moving ave loss 16.354068781362848\n",
            "step 313 - loss 15.242938041687012 - moving ave loss 16.242955707395264\n",
            "step 314 - loss 15.205143928527832 - moving ave loss 16.13917452950852\n",
            "step 315 - loss 14.266050338745117 - moving ave loss 15.951862110432181\n",
            "Finish 13 epoch(es)\n",
            "step 316 - loss 14.528993606567383 - moving ave loss 15.809575260045701\n",
            "step 317 - loss 14.781072616577148 - moving ave loss 15.706724995698847\n",
            "step 318 - loss 16.004179000854492 - moving ave loss 15.736470396214413\n",
            "step 319 - loss 14.956295013427734 - moving ave loss 15.658452857935746\n",
            "step 320 - loss 14.73959732055664 - moving ave loss 15.566567304197836\n",
            "Finish 14 epoch(es)\n",
            "step 321 - loss 14.795896530151367 - moving ave loss 15.48950022679319\n",
            "step 322 - loss 14.351848602294922 - moving ave loss 15.375735064343363\n",
            "step 323 - loss 15.81226921081543 - moving ave loss 15.41938847899057\n",
            "step 324 - loss 15.818723678588867 - moving ave loss 15.4593219989504\n",
            "step 325 - loss 14.226240158081055 - moving ave loss 15.336013814863467\n",
            "Finish 15 epoch(es)\n",
            "step 326 - loss 13.608299255371094 - moving ave loss 15.16324235891423\n",
            "step 327 - loss 15.417638778686523 - moving ave loss 15.18868200089146\n",
            "step 328 - loss 15.163810729980469 - moving ave loss 15.18619487380036\n",
            "step 329 - loss 12.663235664367676 - moving ave loss 14.933898952857092\n",
            "step 330 - loss 14.07717514038086 - moving ave loss 14.84822657160947\n",
            "Finish 16 epoch(es)\n",
            "step 331 - loss 14.230932235717773 - moving ave loss 14.7864971380203\n",
            "step 332 - loss 13.862283706665039 - moving ave loss 14.694075794884775\n",
            "step 333 - loss 14.10228443145752 - moving ave loss 14.63489665854205\n",
            "step 334 - loss 13.572638511657715 - moving ave loss 14.528670843853618\n",
            "step 335 - loss 14.418266296386719 - moving ave loss 14.517630389106928\n",
            "Finish 17 epoch(es)\n",
            "step 336 - loss 13.3367919921875 - moving ave loss 14.399546549414985\n",
            "step 337 - loss 13.745294570922852 - moving ave loss 14.334121351565772\n",
            "step 338 - loss 13.859855651855469 - moving ave loss 14.286694781594743\n",
            "step 339 - loss 13.558164596557617 - moving ave loss 14.21384176309103\n",
            "step 340 - loss 12.847969055175781 - moving ave loss 14.077254492299506\n",
            "Finish 18 epoch(es)\n",
            "step 341 - loss 13.889123916625977 - moving ave loss 14.058441434732153\n",
            "step 342 - loss 12.421747207641602 - moving ave loss 13.894772012023097\n",
            "step 343 - loss 12.57984733581543 - moving ave loss 13.76327954440233\n",
            "step 344 - loss 13.518716812133789 - moving ave loss 13.738823271175477\n",
            "step 345 - loss 12.449983596801758 - moving ave loss 13.609939303738106\n",
            "Finish 19 epoch(es)\n",
            "step 346 - loss 13.295564651489258 - moving ave loss 13.57850183851322\n",
            "step 347 - loss 14.050710678100586 - moving ave loss 13.625722722471957\n",
            "step 348 - loss 12.947181701660156 - moving ave loss 13.557868620390778\n",
            "step 349 - loss 12.980912208557129 - moving ave loss 13.500172979207415\n",
            "step 350 - loss 12.174810409545898 - moving ave loss 13.367636722241263\n",
            "Finish 20 epoch(es)\n",
            "step 351 - loss 12.007708549499512 - moving ave loss 13.231643904967088\n",
            "step 352 - loss 12.148856163024902 - moving ave loss 13.12336513077287\n",
            "step 353 - loss 12.673224449157715 - moving ave loss 13.078351062611354\n",
            "step 354 - loss 13.572813034057617 - moving ave loss 13.12779725975598\n",
            "step 355 - loss 11.799493789672852 - moving ave loss 12.994966912747667\n",
            "Finish 21 epoch(es)\n",
            "step 356 - loss 12.48923110961914 - moving ave loss 12.944393332434815\n",
            "step 357 - loss 11.76574420928955 - moving ave loss 12.826528420120288\n",
            "step 358 - loss 11.837312698364258 - moving ave loss 12.727606847944685\n",
            "step 359 - loss 12.376809120178223 - moving ave loss 12.692527075168039\n",
            "step 360 - loss 11.509981155395508 - moving ave loss 12.574272483190786\n",
            "Finish 22 epoch(es)\n",
            "step 361 - loss 11.659570693969727 - moving ave loss 12.482802304268679\n",
            "step 362 - loss 11.293719291687012 - moving ave loss 12.363894003010513\n",
            "step 363 - loss 11.379850387573242 - moving ave loss 12.265489641466786\n",
            "step 364 - loss 12.774633407592773 - moving ave loss 12.316404018079385\n",
            "step 365 - loss 11.432135581970215 - moving ave loss 12.227977174468469\n",
            "Finish 23 epoch(es)\n",
            "step 366 - loss 12.246061325073242 - moving ave loss 12.229785589528946\n",
            "step 367 - loss 12.370192527770996 - moving ave loss 12.243826283353151\n",
            "step 368 - loss 10.654707908630371 - moving ave loss 12.084914445880873\n",
            "step 369 - loss 10.703571319580078 - moving ave loss 11.946780133250794\n",
            "step 370 - loss 12.385000228881836 - moving ave loss 11.990602142813898\n",
            "Finish 24 epoch(es)\n",
            "step 371 - loss 11.611706733703613 - moving ave loss 11.952712601902869\n",
            "step 372 - loss 11.192276954650879 - moving ave loss 11.87666903717767\n",
            "step 373 - loss 11.723299026489258 - moving ave loss 11.861332036108829\n",
            "step 374 - loss 11.585813522338867 - moving ave loss 11.833780184731832\n",
            "step 375 - loss 10.595775604248047 - moving ave loss 11.709979726683454\n",
            "Checkpoint at step 375\n",
            "Finish 25 epoch(es)\n",
            "step 376 - loss 11.36578369140625 - moving ave loss 11.675560123155734\n",
            "step 377 - loss 10.31291675567627 - moving ave loss 11.539295786407786\n",
            "step 378 - loss 10.852117538452148 - moving ave loss 11.470577961612223\n",
            "step 379 - loss 10.746881484985352 - moving ave loss 11.398208313949535\n",
            "step 380 - loss 10.555281639099121 - moving ave loss 11.313915646464494\n",
            "Finish 26 epoch(es)\n",
            "step 381 - loss 10.648536682128906 - moving ave loss 11.247377750030935\n",
            "step 382 - loss 10.570611000061035 - moving ave loss 11.179701075033947\n",
            "step 383 - loss 9.648364067077637 - moving ave loss 11.026567374238317\n",
            "step 384 - loss 11.339784622192383 - moving ave loss 11.057889099033723\n",
            "step 385 - loss 9.947366714477539 - moving ave loss 10.946836860578104\n",
            "Finish 27 epoch(es)\n",
            "step 386 - loss 9.841752052307129 - moving ave loss 10.836328379751007\n",
            "step 387 - loss 10.667704582214355 - moving ave loss 10.819465999997343\n",
            "step 388 - loss 10.014534950256348 - moving ave loss 10.738972895023243\n",
            "step 389 - loss 10.486729621887207 - moving ave loss 10.71374856770964\n",
            "step 390 - loss 10.456571578979492 - moving ave loss 10.688030868836625\n",
            "Finish 28 epoch(es)\n",
            "step 391 - loss 9.643401145935059 - moving ave loss 10.58356789654647\n",
            "step 392 - loss 9.257349014282227 - moving ave loss 10.450946008320045\n",
            "step 393 - loss 9.998466491699219 - moving ave loss 10.405698056657963\n",
            "step 394 - loss 10.863570213317871 - moving ave loss 10.451485272323954\n",
            "step 395 - loss 9.075428009033203 - moving ave loss 10.313879545994878\n",
            "Finish 29 epoch(es)\n",
            "step 396 - loss 10.61367416381836 - moving ave loss 10.343859007777226\n",
            "step 397 - loss 9.953629493713379 - moving ave loss 10.30483605637084\n",
            "step 398 - loss 9.327123641967773 - moving ave loss 10.207064814930535\n",
            "step 399 - loss 9.090353012084961 - moving ave loss 10.095393634645976\n",
            "step 400 - loss 9.407930374145508 - moving ave loss 10.02664730859593\n",
            "Finish 30 epoch(es)\n",
            "step 401 - loss 9.238391876220703 - moving ave loss 9.947821765358407\n",
            "step 402 - loss 9.690690040588379 - moving ave loss 9.922108592881404\n",
            "step 403 - loss 9.155040740966797 - moving ave loss 9.845401807689944\n",
            "step 404 - loss 10.22120189666748 - moving ave loss 9.882981816587698\n",
            "step 405 - loss 8.917953491210938 - moving ave loss 9.78647898405002\n",
            "Finish 31 epoch(es)\n",
            "step 406 - loss 8.894707679748535 - moving ave loss 9.697301853619871\n",
            "step 407 - loss 10.329797744750977 - moving ave loss 9.760551442732982\n",
            "step 408 - loss 9.11566162109375 - moving ave loss 9.69606246056906\n",
            "step 409 - loss 9.402332305908203 - moving ave loss 9.666689445102975\n",
            "step 410 - loss 9.58956527709961 - moving ave loss 9.658977028302639\n",
            "Finish 32 epoch(es)\n",
            "step 411 - loss 8.392374038696289 - moving ave loss 9.532316729342003\n",
            "step 412 - loss 9.666030883789062 - moving ave loss 9.54568814478671\n",
            "step 413 - loss 8.436182975769043 - moving ave loss 9.434737627884944\n",
            "step 414 - loss 9.632368087768555 - moving ave loss 9.454500673873305\n",
            "step 415 - loss 8.348411560058594 - moving ave loss 9.343891762491834\n",
            "Finish 33 epoch(es)\n",
            "step 416 - loss 8.558700561523438 - moving ave loss 9.265372642394995\n",
            "step 417 - loss 9.42072582244873 - moving ave loss 9.280907960400368\n",
            "step 418 - loss 8.1931734085083 - moving ave loss 9.172134505211162\n",
            "step 419 - loss 8.177957534790039 - moving ave loss 9.07271680816905\n",
            "step 420 - loss 8.797262191772461 - moving ave loss 9.045171346529392\n",
            "Finish 34 epoch(es)\n",
            "step 421 - loss 8.900104522705078 - moving ave loss 9.03066466414696\n",
            "step 422 - loss 9.174576759338379 - moving ave loss 9.0450558736661\n",
            "step 423 - loss 8.925987243652344 - moving ave loss 9.033149010664726\n",
            "step 424 - loss 8.16087818145752 - moving ave loss 8.945921927744005\n",
            "step 425 - loss 7.72456169128418 - moving ave loss 8.823785904098022\n",
            "Finish 35 epoch(es)\n",
            "step 426 - loss 7.415579795837402 - moving ave loss 8.68296529327196\n",
            "step 427 - loss 8.870465278625488 - moving ave loss 8.701715291807313\n",
            "step 428 - loss 7.751551628112793 - moving ave loss 8.606698925437861\n",
            "step 429 - loss 9.331268310546875 - moving ave loss 8.679155863948763\n",
            "step 430 - loss 7.72486686706543 - moving ave loss 8.58372696426043\n",
            "Finish 36 epoch(es)\n",
            "step 431 - loss 8.049015998840332 - moving ave loss 8.53025586771842\n",
            "step 432 - loss 7.7496490478515625 - moving ave loss 8.452195185731735\n",
            "step 433 - loss 8.170907020568848 - moving ave loss 8.424066369215447\n",
            "step 434 - loss 9.538232803344727 - moving ave loss 8.535483012628376\n",
            "step 435 - loss 7.475634574890137 - moving ave loss 8.429498168854552\n",
            "Finish 37 epoch(es)\n",
            "step 436 - loss 7.559950828552246 - moving ave loss 8.342543434824321\n",
            "step 437 - loss 8.222475051879883 - moving ave loss 8.330536596529878\n",
            "step 438 - loss 7.8358588218688965 - moving ave loss 8.28106881906378\n",
            "step 439 - loss 7.386108875274658 - moving ave loss 8.191572824684867\n",
            "step 440 - loss 7.96055793762207 - moving ave loss 8.168471335978587\n",
            "Finish 38 epoch(es)\n",
            "step 441 - loss 8.376838684082031 - moving ave loss 8.189308070788933\n",
            "step 442 - loss 7.421836853027344 - moving ave loss 8.112560949012774\n",
            "step 443 - loss 8.792085647583008 - moving ave loss 8.180513418869797\n",
            "step 444 - loss 6.788767337799072 - moving ave loss 8.041338810762724\n",
            "step 445 - loss 7.571425437927246 - moving ave loss 7.994347473479176\n",
            "Finish 39 epoch(es)\n",
            "step 446 - loss 8.265191078186035 - moving ave loss 8.021431833949862\n",
            "step 447 - loss 7.5504045486450195 - moving ave loss 7.974329105419377\n",
            "step 448 - loss 7.478227138519287 - moving ave loss 7.924718908729369\n",
            "step 449 - loss 7.830911636352539 - moving ave loss 7.915338181491686\n",
            "step 450 - loss 7.102539539337158 - moving ave loss 7.8340583172762335\n",
            "Finish 40 epoch(es)\n",
            "step 451 - loss 6.728058338165283 - moving ave loss 7.723458319365139\n",
            "step 452 - loss 6.550994396209717 - moving ave loss 7.606211927049596\n",
            "step 453 - loss 7.417297840118408 - moving ave loss 7.587320518356478\n",
            "step 454 - loss 7.602560043334961 - moving ave loss 7.588844470854326\n",
            "step 455 - loss 8.676225662231445 - moving ave loss 7.697582589992038\n",
            "Finish 41 epoch(es)\n",
            "step 456 - loss 7.24739933013916 - moving ave loss 7.652564264006751\n",
            "step 457 - loss 8.37930679321289 - moving ave loss 7.725238516927365\n",
            "step 458 - loss 7.319864273071289 - moving ave loss 7.684701092541758\n",
            "step 459 - loss 6.963234901428223 - moving ave loss 7.612554473430405\n",
            "step 460 - loss 7.059410572052002 - moving ave loss 7.557240083292566\n",
            "Finish 42 epoch(es)\n",
            "step 461 - loss 7.070732116699219 - moving ave loss 7.5085892866332316\n",
            "step 462 - loss 7.143868923187256 - moving ave loss 7.472117250288634\n",
            "step 463 - loss 7.434268474578857 - moving ave loss 7.468332372717656\n",
            "step 464 - loss 6.126963138580322 - moving ave loss 7.334195449303923\n",
            "step 465 - loss 7.33809757232666 - moving ave loss 7.334585661606197\n",
            "Finish 43 epoch(es)\n",
            "step 466 - loss 6.793400287628174 - moving ave loss 7.280467124208395\n",
            "step 467 - loss 6.35659122467041 - moving ave loss 7.188079534254597\n",
            "step 468 - loss 6.519571304321289 - moving ave loss 7.121228711261267\n",
            "step 469 - loss 7.486481666564941 - moving ave loss 7.1577540067916345\n",
            "step 470 - loss 7.000018119812012 - moving ave loss 7.141980418093672\n",
            "Finish 44 epoch(es)\n",
            "step 471 - loss 6.256915092468262 - moving ave loss 7.053473885531131\n",
            "step 472 - loss 6.61995792388916 - moving ave loss 7.010122289366935\n",
            "step 473 - loss 7.261229038238525 - moving ave loss 7.035232964254094\n",
            "step 474 - loss 7.541016578674316 - moving ave loss 7.085811325696117\n",
            "step 475 - loss 6.869459629058838 - moving ave loss 7.064176156032389\n",
            "Finish 45 epoch(es)\n",
            "step 476 - loss 7.308744430541992 - moving ave loss 7.0886329834833495\n",
            "step 477 - loss 6.661708831787109 - moving ave loss 7.045940568313726\n",
            "step 478 - loss 5.444051742553711 - moving ave loss 6.885751685737724\n",
            "step 479 - loss 5.768216133117676 - moving ave loss 6.77399813047572\n",
            "step 480 - loss 6.9927473068237305 - moving ave loss 6.795873048110521\n",
            "Finish 46 epoch(es)\n",
            "step 481 - loss 5.584244728088379 - moving ave loss 6.674710216108307\n",
            "step 482 - loss 6.009184837341309 - moving ave loss 6.608157678231608\n",
            "step 483 - loss 6.392307281494141 - moving ave loss 6.586572638557861\n",
            "step 484 - loss 5.961012840270996 - moving ave loss 6.524016658729175\n",
            "step 485 - loss 7.435420036315918 - moving ave loss 6.615156996487849\n",
            "Finish 47 epoch(es)\n",
            "step 486 - loss 6.123424530029297 - moving ave loss 6.565983749841994\n",
            "step 487 - loss 5.9174675941467285 - moving ave loss 6.501132134272468\n",
            "step 488 - loss 6.176895618438721 - moving ave loss 6.4687084826890935\n",
            "step 489 - loss 5.378499507904053 - moving ave loss 6.359687585210589\n",
            "step 490 - loss 6.543090343475342 - moving ave loss 6.378027861037065\n",
            "Finish 48 epoch(es)\n",
            "step 491 - loss 6.345202445983887 - moving ave loss 6.374745319531748\n",
            "step 492 - loss 5.735049247741699 - moving ave loss 6.310775712352743\n",
            "step 493 - loss 6.11932897567749 - moving ave loss 6.2916310386852174\n",
            "step 494 - loss 6.033736228942871 - moving ave loss 6.265841557710983\n",
            "step 495 - loss 6.541316986083984 - moving ave loss 6.293389100548283\n",
            "Finish 49 epoch(es)\n",
            "step 496 - loss 6.170881271362305 - moving ave loss 6.281138317629685\n",
            "step 497 - loss 5.694573402404785 - moving ave loss 6.222481826107194\n",
            "step 498 - loss 6.856377124786377 - moving ave loss 6.285871355975113\n",
            "step 499 - loss 5.792101860046387 - moving ave loss 6.23649440638224\n",
            "step 500 - loss 5.5135297775268555 - moving ave loss 6.164197943496702\n",
            "Checkpoint at step 500\n",
            "Finish 50 epoch(es)\n",
            "step 501 - loss 5.5423054695129395 - moving ave loss 6.102008696098325\n",
            "step 502 - loss 5.263532638549805 - moving ave loss 6.018161090343474\n",
            "step 503 - loss 6.195777893066406 - moving ave loss 6.035922770615768\n",
            "step 504 - loss 6.046214580535889 - moving ave loss 6.03695195160778\n",
            "step 505 - loss 6.488615036010742 - moving ave loss 6.082118260048077\n",
            "Finish 51 epoch(es)\n",
            "step 506 - loss 5.546629905700684 - moving ave loss 6.0285694246133374\n",
            "step 507 - loss 6.417939186096191 - moving ave loss 6.067506400761623\n",
            "step 508 - loss 5.340948104858398 - moving ave loss 5.994850571171301\n",
            "step 509 - loss 5.542745113372803 - moving ave loss 5.949640025391451\n",
            "step 510 - loss 5.650972366333008 - moving ave loss 5.919773259485607\n",
            "Finish 52 epoch(es)\n",
            "step 511 - loss 5.9311842918396 - moving ave loss 5.920914362721007\n",
            "step 512 - loss 6.481511116027832 - moving ave loss 5.97697403805169\n",
            "step 513 - loss 5.188579559326172 - moving ave loss 5.898134590179138\n",
            "step 514 - loss 5.301612854003906 - moving ave loss 5.838482416561615\n",
            "step 515 - loss 5.521461009979248 - moving ave loss 5.806780275903379\n",
            "Finish 53 epoch(es)\n",
            "step 516 - loss 4.606453895568848 - moving ave loss 5.686747637869926\n",
            "step 517 - loss 5.195849895477295 - moving ave loss 5.637657863630663\n",
            "step 518 - loss 5.862644195556641 - moving ave loss 5.6601564968232605\n",
            "step 519 - loss 5.842832088470459 - moving ave loss 5.67842405598798\n",
            "step 520 - loss 5.445882320404053 - moving ave loss 5.655169882429588\n",
            "Finish 54 epoch(es)\n",
            "step 521 - loss 4.662343978881836 - moving ave loss 5.5558872920748135\n",
            "step 522 - loss 6.076394081115723 - moving ave loss 5.607937970978904\n",
            "step 523 - loss 6.086908340454102 - moving ave loss 5.655835007926424\n",
            "step 524 - loss 5.501588821411133 - moving ave loss 5.640410389274895\n",
            "step 525 - loss 4.990865707397461 - moving ave loss 5.575455921087152\n",
            "Finish 55 epoch(es)\n",
            "step 526 - loss 4.9978718757629395 - moving ave loss 5.517697516554731\n",
            "step 527 - loss 6.381858825683594 - moving ave loss 5.604113647467617\n",
            "step 528 - loss 5.429074287414551 - moving ave loss 5.586609711462311\n",
            "step 529 - loss 5.475192070007324 - moving ave loss 5.575467947316812\n",
            "step 530 - loss 5.325533866882324 - moving ave loss 5.550474539273364\n",
            "Finish 56 epoch(es)\n",
            "step 531 - loss 5.728323936462402 - moving ave loss 5.5682594789922675\n",
            "step 532 - loss 4.518537521362305 - moving ave loss 5.463287283229271\n",
            "step 533 - loss 4.581943511962891 - moving ave loss 5.375152906102633\n",
            "step 534 - loss 4.930356502532959 - moving ave loss 5.3306732657456655\n",
            "step 535 - loss 5.425107479095459 - moving ave loss 5.340116687080645\n",
            "Finish 57 epoch(es)\n",
            "step 536 - loss 4.577516555786133 - moving ave loss 5.263856673951194\n",
            "step 537 - loss 6.020975112915039 - moving ave loss 5.339568517847579\n",
            "step 538 - loss 5.001946449279785 - moving ave loss 5.305806310990799\n",
            "step 539 - loss 5.381900310516357 - moving ave loss 5.313415710943355\n",
            "step 540 - loss 4.428993225097656 - moving ave loss 5.2249734623587845\n",
            "Finish 58 epoch(es)\n",
            "step 541 - loss 4.838633060455322 - moving ave loss 5.186339422168438\n",
            "step 542 - loss 5.323531150817871 - moving ave loss 5.200058595033382\n",
            "step 543 - loss 4.3604278564453125 - moving ave loss 5.116095521174575\n",
            "step 544 - loss 5.184734344482422 - moving ave loss 5.12295940350536\n",
            "step 545 - loss 4.23928165435791 - moving ave loss 5.034591628590615\n",
            "Finish 59 epoch(es)\n",
            "step 546 - loss 4.778201103210449 - moving ave loss 5.008952576052598\n",
            "step 547 - loss 4.966434955596924 - moving ave loss 5.004700814007031\n",
            "step 548 - loss 4.51193904876709 - moving ave loss 4.955424637483037\n",
            "step 549 - loss 4.179348468780518 - moving ave loss 4.8778170206127855\n",
            "step 550 - loss 5.690639972686768 - moving ave loss 4.9590993158201835\n",
            "Finish 60 epoch(es)\n",
            "step 551 - loss 4.527280330657959 - moving ave loss 4.9159174173039615\n",
            "step 552 - loss 4.877076148986816 - moving ave loss 4.912033290472247\n",
            "step 553 - loss 4.940413475036621 - moving ave loss 4.914871308928685\n",
            "step 554 - loss 5.6509904861450195 - moving ave loss 4.9884832266503185\n",
            "step 555 - loss 4.101659774780273 - moving ave loss 4.899800881463315\n",
            "Finish 61 epoch(es)\n",
            "step 556 - loss 4.957867622375488 - moving ave loss 4.905607555554532\n",
            "step 557 - loss 5.612804889678955 - moving ave loss 4.976327288966974\n",
            "step 558 - loss 3.824848175048828 - moving ave loss 4.86117937757516\n",
            "step 559 - loss 4.470037937164307 - moving ave loss 4.822065233534075\n",
            "step 560 - loss 4.685367584228516 - moving ave loss 4.8083954686035195\n",
            "Finish 62 epoch(es)\n",
            "step 561 - loss 4.818386554718018 - moving ave loss 4.809394577214969\n",
            "step 562 - loss 4.901871681213379 - moving ave loss 4.818642287614811\n",
            "step 563 - loss 4.348359107971191 - moving ave loss 4.771613969650449\n",
            "step 564 - loss 4.389191627502441 - moving ave loss 4.733371735435648\n",
            "step 565 - loss 5.182989597320557 - moving ave loss 4.778333521624139\n",
            "Finish 63 epoch(es)\n",
            "step 566 - loss 5.026065349578857 - moving ave loss 4.803106704419612\n",
            "step 567 - loss 4.132193565368652 - moving ave loss 4.736015390514517\n",
            "step 568 - loss 4.699995040893555 - moving ave loss 4.732413355552421\n",
            "step 569 - loss 3.7682323455810547 - moving ave loss 4.635995254555284\n",
            "step 570 - loss 4.5010294914245605 - moving ave loss 4.622498678242212\n",
            "Finish 64 epoch(es)\n",
            "step 571 - loss 3.945546865463257 - moving ave loss 4.5548034969643165\n",
            "step 572 - loss 4.303168296813965 - moving ave loss 4.529639976949282\n",
            "step 573 - loss 4.223156929016113 - moving ave loss 4.498991672155965\n",
            "step 574 - loss 5.255003929138184 - moving ave loss 4.5745928978541865\n",
            "step 575 - loss 4.807910919189453 - moving ave loss 4.597924699987713\n",
            "Finish 65 epoch(es)\n",
            "step 576 - loss 5.247882843017578 - moving ave loss 4.6629205142907\n",
            "step 577 - loss 4.00532341003418 - moving ave loss 4.597160803865048\n",
            "step 578 - loss 3.7434489727020264 - moving ave loss 4.511789620748746\n",
            "step 579 - loss 4.010418891906738 - moving ave loss 4.461652547864546\n",
            "step 580 - loss 5.261087417602539 - moving ave loss 4.541596034838345\n",
            "Finish 66 epoch(es)\n",
            "step 581 - loss 5.4822998046875 - moving ave loss 4.6356664118232604\n",
            "step 582 - loss 4.337136745452881 - moving ave loss 4.6058134451862225\n",
            "step 583 - loss 4.480599403381348 - moving ave loss 4.593292041005736\n",
            "step 584 - loss 3.512873411178589 - moving ave loss 4.485250178023021\n",
            "step 585 - loss 3.903979539871216 - moving ave loss 4.42712311420784\n",
            "Finish 67 epoch(es)\n",
            "step 586 - loss 5.371744155883789 - moving ave loss 4.521585218375435\n",
            "step 587 - loss 3.6853723526000977 - moving ave loss 4.437963931797901\n",
            "step 588 - loss 4.149838447570801 - moving ave loss 4.409151383375191\n",
            "step 589 - loss 4.30679988861084 - moving ave loss 4.398916233898755\n",
            "step 590 - loss 3.907874345779419 - moving ave loss 4.349812045086821\n",
            "Finish 68 epoch(es)\n",
            "step 591 - loss 4.4802656173706055 - moving ave loss 4.3628574023152\n",
            "step 592 - loss 4.447534561157227 - moving ave loss 4.371325118199403\n",
            "step 593 - loss 4.227130889892578 - moving ave loss 4.35690569536872\n",
            "step 594 - loss 4.626767158508301 - moving ave loss 4.383891841682678\n",
            "step 595 - loss 3.502044677734375 - moving ave loss 4.295707125287848\n",
            "Finish 69 epoch(es)\n",
            "step 596 - loss 4.727135181427002 - moving ave loss 4.338849930901763\n",
            "step 597 - loss 3.859013557434082 - moving ave loss 4.290866293554996\n",
            "step 598 - loss 3.3518106937408447 - moving ave loss 4.19696073357358\n",
            "step 599 - loss 3.7593469619750977 - moving ave loss 4.153199356413732\n",
            "step 600 - loss 3.8628578186035156 - moving ave loss 4.12416520263271\n",
            "Finish 70 epoch(es)\n",
            "step 601 - loss 4.099326133728027 - moving ave loss 4.121681295742242\n",
            "step 602 - loss 4.334469795227051 - moving ave loss 4.142960145690723\n",
            "step 603 - loss 4.450420379638672 - moving ave loss 4.173706169085518\n",
            "step 604 - loss 4.221397399902344 - moving ave loss 4.1784752921672\n",
            "step 605 - loss 3.5225086212158203 - moving ave loss 4.112878625072063\n",
            "Finish 71 epoch(es)\n",
            "step 606 - loss 3.7826805114746094 - moving ave loss 4.079858813712318\n",
            "step 607 - loss 3.8227121829986572 - moving ave loss 4.054144150640952\n",
            "step 608 - loss 5.169087886810303 - moving ave loss 4.165638524257887\n",
            "step 609 - loss 4.495601654052734 - moving ave loss 4.198634837237372\n",
            "step 610 - loss 3.5462584495544434 - moving ave loss 4.13339719846908\n",
            "Finish 72 epoch(es)\n",
            "step 611 - loss 4.082825183868408 - moving ave loss 4.128339997009013\n",
            "step 612 - loss 3.490264892578125 - moving ave loss 4.064532486565924\n",
            "step 613 - loss 3.5182461738586426 - moving ave loss 4.009903855295196\n",
            "step 614 - loss 3.8937008380889893 - moving ave loss 3.9982835535745753\n",
            "step 615 - loss 3.7611594200134277 - moving ave loss 3.9745711402184605\n",
            "Finish 73 epoch(es)\n",
            "step 616 - loss 3.178663730621338 - moving ave loss 3.894980399258748\n",
            "step 617 - loss 3.807987928390503 - moving ave loss 3.886281152171924\n",
            "step 618 - loss 4.036438465118408 - moving ave loss 3.901296883466572\n",
            "step 619 - loss 5.674057960510254 - moving ave loss 4.07857299117094\n",
            "step 620 - loss 3.0036938190460205 - moving ave loss 3.9710850739584482\n",
            "Finish 74 epoch(es)\n",
            "step 621 - loss 4.011086463928223 - moving ave loss 3.9750852129554257\n",
            "step 622 - loss 3.4143729209899902 - moving ave loss 3.9190139837588824\n",
            "step 623 - loss 3.7758305072784424 - moving ave loss 3.9046956361108385\n",
            "step 624 - loss 3.6433072090148926 - moving ave loss 3.878556793401244\n",
            "step 625 - loss 4.221654891967773 - moving ave loss 3.912866603257897\n",
            "Checkpoint at step 625\n",
            "Finish 75 epoch(es)\n",
            "step 626 - loss 3.3683907985687256 - moving ave loss 3.85841902278898\n",
            "step 627 - loss 5.014917373657227 - moving ave loss 3.974068857875805\n",
            "step 628 - loss 3.4583282470703125 - moving ave loss 3.922494796795256\n",
            "step 629 - loss 3.4322822093963623 - moving ave loss 3.8734735380553666\n",
            "step 630 - loss 3.514893054962158 - moving ave loss 3.837615489746046\n",
            "Finish 76 epoch(es)\n",
            "step 631 - loss 3.7295212745666504 - moving ave loss 3.826806068228106\n",
            "step 632 - loss 3.931076765060425 - moving ave loss 3.8372331379113382\n",
            "step 633 - loss 3.5253818035125732 - moving ave loss 3.806048004471462\n",
            "step 634 - loss 4.524310111999512 - moving ave loss 3.877874215224267\n",
            "step 635 - loss 3.2484235763549805 - moving ave loss 3.8149291513373385\n",
            "Finish 77 epoch(es)\n",
            "step 636 - loss 3.0629422664642334 - moving ave loss 3.739730462850028\n",
            "step 637 - loss 3.613706350326538 - moving ave loss 3.727128051597679\n",
            "step 638 - loss 3.9194188117980957 - moving ave loss 3.746357127617721\n",
            "step 639 - loss 3.7849674224853516 - moving ave loss 3.7502181571044844\n",
            "step 640 - loss 3.919358253479004 - moving ave loss 3.7671321667419364\n",
            "Finish 78 epoch(es)\n",
            "step 641 - loss 3.5541110038757324 - moving ave loss 3.745830050455316\n",
            "step 642 - loss 4.566235065460205 - moving ave loss 3.8278705519558054\n",
            "step 643 - loss 2.773754119873047 - moving ave loss 3.7224589087475297\n",
            "step 644 - loss 3.311677932739258 - moving ave loss 3.6813808111467026\n",
            "step 645 - loss 3.2671732902526855 - moving ave loss 3.639960059057301\n",
            "Finish 79 epoch(es)\n",
            "step 646 - loss 3.4824373722076416 - moving ave loss 3.6242077903723353\n",
            "step 647 - loss 3.7052245140075684 - moving ave loss 3.6323094627358588\n",
            "step 648 - loss 3.003310203552246 - moving ave loss 3.5694095368174974\n",
            "step 649 - loss 2.7911858558654785 - moving ave loss 3.4915871687222952\n",
            "step 650 - loss 3.336244821548462 - moving ave loss 3.4760529340049118\n",
            "Finish 80 epoch(es)\n",
            "step 651 - loss 2.848562240600586 - moving ave loss 3.413303864664479\n",
            "step 652 - loss 3.2409911155700684 - moving ave loss 3.396072589755038\n",
            "step 653 - loss 4.074333667755127 - moving ave loss 3.463898697555047\n",
            "step 654 - loss 4.157072067260742 - moving ave loss 3.5332160345256165\n",
            "step 655 - loss 2.424267292022705 - moving ave loss 3.4223211602753256\n",
            "Finish 81 epoch(es)\n",
            "step 656 - loss 3.393371820449829 - moving ave loss 3.419426226292776\n",
            "step 657 - loss 3.64907169342041 - moving ave loss 3.4423907730055396\n",
            "step 658 - loss 2.863671064376831 - moving ave loss 3.3845188021426686\n",
            "step 659 - loss 3.8221592903137207 - moving ave loss 3.428282850959774\n",
            "step 660 - loss 2.7756705284118652 - moving ave loss 3.363021618704983\n",
            "Finish 82 epoch(es)\n",
            "step 661 - loss 3.626605987548828 - moving ave loss 3.389380055589368\n",
            "step 662 - loss 2.9283084869384766 - moving ave loss 3.343272898724279\n",
            "step 663 - loss 3.210848331451416 - moving ave loss 3.3300304419969926\n",
            "step 664 - loss 3.0964956283569336 - moving ave loss 3.306676960632987\n",
            "step 665 - loss 4.402552127838135 - moving ave loss 3.4162644773535016\n",
            "Finish 83 epoch(es)\n",
            "step 666 - loss 3.9140286445617676 - moving ave loss 3.4660408940743284\n",
            "step 667 - loss 3.02693772315979 - moving ave loss 3.422130576982875\n",
            "step 668 - loss 3.2594168186187744 - moving ave loss 3.405859201146465\n",
            "step 669 - loss 2.9963440895080566 - moving ave loss 3.364907689982624\n",
            "step 670 - loss 2.8613784313201904 - moving ave loss 3.3145547641163806\n",
            "Finish 84 epoch(es)\n",
            "step 671 - loss 4.369270324707031 - moving ave loss 3.4200263201754457\n",
            "step 672 - loss 2.9641001224517822 - moving ave loss 3.3744337004030793\n",
            "step 673 - loss 2.50374174118042 - moving ave loss 3.2873645044808137\n",
            "step 674 - loss 3.455336093902588 - moving ave loss 3.3041616634229913\n",
            "step 675 - loss 4.085075855255127 - moving ave loss 3.382253082606205\n",
            "Finish 85 epoch(es)\n",
            "step 676 - loss 3.0211448669433594 - moving ave loss 3.3461422610399203\n",
            "step 677 - loss 3.1747384071350098 - moving ave loss 3.3290018756494293\n",
            "step 678 - loss 3.059173345565796 - moving ave loss 3.3020190226410664\n",
            "step 679 - loss 3.7458066940307617 - moving ave loss 3.3463977897800357\n",
            "step 680 - loss 3.026230812072754 - moving ave loss 3.3143810920093077\n",
            "Finish 86 epoch(es)\n",
            "step 681 - loss 3.562140464782715 - moving ave loss 3.3391570292866484\n",
            "step 682 - loss 2.904902696609497 - moving ave loss 3.2957315960189333\n",
            "step 683 - loss 2.8957223892211914 - moving ave loss 3.255730675339159\n",
            "step 684 - loss 3.298685073852539 - moving ave loss 3.2600261151904975\n",
            "step 685 - loss 3.7570831775665283 - moving ave loss 3.309731821428101\n",
            "Finish 87 epoch(es)\n",
            "step 686 - loss 3.429218292236328 - moving ave loss 3.321680468508924\n",
            "step 687 - loss 2.946321964263916 - moving ave loss 3.284144618084423\n",
            "step 688 - loss 2.760291576385498 - moving ave loss 3.2317593139145306\n",
            "step 689 - loss 2.808772087097168 - moving ave loss 3.1894605912327947\n",
            "step 690 - loss 3.826852321624756 - moving ave loss 3.253199764271991\n",
            "Finish 88 epoch(es)\n",
            "step 691 - loss 4.2969818115234375 - moving ave loss 3.357577968997136\n",
            "step 692 - loss 3.2053370475769043 - moving ave loss 3.342353876855113\n",
            "step 693 - loss 3.1023812294006348 - moving ave loss 3.3183566121096653\n",
            "step 694 - loss 3.018932819366455 - moving ave loss 3.2884142328353443\n",
            "step 695 - loss 2.3217506408691406 - moving ave loss 3.1917478736387244\n",
            "Finish 89 epoch(es)\n",
            "step 696 - loss 2.490919589996338 - moving ave loss 3.121665045274486\n",
            "step 697 - loss 3.330573558807373 - moving ave loss 3.142555896627775\n",
            "step 698 - loss 4.049901485443115 - moving ave loss 3.233290455509309\n",
            "step 699 - loss 2.8965821266174316 - moving ave loss 3.1996196226201215\n",
            "step 700 - loss 2.82623291015625 - moving ave loss 3.1622809513737344\n",
            "Finish 90 epoch(es)\n",
            "step 701 - loss 3.4103403091430664 - moving ave loss 3.187086887150668\n",
            "step 702 - loss 3.0841827392578125 - moving ave loss 3.1767964723613824\n",
            "step 703 - loss 2.7113471031188965 - moving ave loss 3.130251535437134\n",
            "step 704 - loss 3.5883896350860596 - moving ave loss 3.1760653454020265\n",
            "step 705 - loss 2.583784580230713 - moving ave loss 3.1168372688848955\n",
            "Finish 91 epoch(es)\n",
            "step 706 - loss 2.6452596187591553 - moving ave loss 3.069679503872322\n",
            "step 707 - loss 2.3921926021575928 - moving ave loss 3.001930813700849\n",
            "step 708 - loss 2.766730308532715 - moving ave loss 2.9784107631840357\n",
            "step 709 - loss 3.6422629356384277 - moving ave loss 3.044795980429475\n",
            "step 710 - loss 2.855839490890503 - moving ave loss 3.025900331475578\n",
            "Finish 92 epoch(es)\n",
            "step 711 - loss 3.3082058429718018 - moving ave loss 3.0541308826252003\n",
            "step 712 - loss 3.1396496295928955 - moving ave loss 3.0626827573219697\n",
            "step 713 - loss 2.347487211227417 - moving ave loss 2.9911632027125146\n",
            "step 714 - loss 2.409348726272583 - moving ave loss 2.9329817550685213\n",
            "step 715 - loss 3.226260185241699 - moving ave loss 2.962309598085839\n",
            "Finish 93 epoch(es)\n",
            "step 716 - loss 2.1123619079589844 - moving ave loss 2.877314829073154\n",
            "step 717 - loss 4.410181045532227 - moving ave loss 3.030601450719061\n",
            "step 718 - loss 3.336048126220703 - moving ave loss 3.0611461182692254\n",
            "step 719 - loss 2.6434569358825684 - moving ave loss 3.0193772000305596\n",
            "step 720 - loss 2.135329246520996 - moving ave loss 2.9309724046796033\n",
            "Finish 94 epoch(es)\n",
            "step 721 - loss 1.9525530338287354 - moving ave loss 2.8331304675945166\n",
            "step 722 - loss 3.4890308380126953 - moving ave loss 2.8987205046363345\n",
            "step 723 - loss 3.075810670852661 - moving ave loss 2.9164295212579674\n",
            "step 724 - loss 2.878000020980835 - moving ave loss 2.912586571230254\n",
            "step 725 - loss 2.0518503189086914 - moving ave loss 2.8265129459980978\n",
            "Finish 95 epoch(es)\n",
            "step 726 - loss 3.294373035430908 - moving ave loss 2.8732989549413785\n",
            "step 727 - loss 2.776549816131592 - moving ave loss 2.8636240410604\n",
            "step 728 - loss 4.043923377990723 - moving ave loss 2.9816539747534327\n",
            "step 729 - loss 2.5497689247131348 - moving ave loss 2.938465469749403\n",
            "step 730 - loss 2.3826119899749756 - moving ave loss 2.88288012177196\n",
            "Finish 96 epoch(es)\n",
            "step 731 - loss 2.9579145908355713 - moving ave loss 2.8903835686783217\n",
            "step 732 - loss 2.678846597671509 - moving ave loss 2.86922987157764\n",
            "step 733 - loss 3.1356706619262695 - moving ave loss 2.895873950612503\n",
            "step 734 - loss 2.9612274169921875 - moving ave loss 2.9024092972504714\n",
            "step 735 - loss 3.436069965362549 - moving ave loss 2.9557753640616795\n",
            "Finish 97 epoch(es)\n",
            "step 736 - loss 2.1457223892211914 - moving ave loss 2.874770066577631\n",
            "step 737 - loss 2.6539924144744873 - moving ave loss 2.852692301367316\n",
            "step 738 - loss 3.1146788597106934 - moving ave loss 2.878890957201654\n",
            "step 739 - loss 2.5583443641662598 - moving ave loss 2.8468362978981148\n",
            "step 740 - loss 2.68517804145813 - moving ave loss 2.8306704722541167\n",
            "Finish 98 epoch(es)\n",
            "step 741 - loss 2.613049030303955 - moving ave loss 2.8089083280591005\n",
            "step 742 - loss 3.336237668991089 - moving ave loss 2.8616412621522995\n",
            "step 743 - loss 1.8601282835006714 - moving ave loss 2.761489964287137\n",
            "step 744 - loss 2.646361827850342 - moving ave loss 2.749977150643457\n",
            "step 745 - loss 3.315599203109741 - moving ave loss 2.8065393558900857\n",
            "Finish 99 epoch(es)\n",
            "step 746 - loss 2.629253387451172 - moving ave loss 2.7888107590461946\n",
            "step 747 - loss 2.966862678527832 - moving ave loss 2.8066159509943587\n",
            "step 748 - loss 2.810642719268799 - moving ave loss 2.807018627821803\n",
            "step 749 - loss 2.616992950439453 - moving ave loss 2.788016060083568\n",
            "step 750 - loss 3.026534080505371 - moving ave loss 2.8118678621257485\n",
            "Checkpoint at step 750\n",
            "Finish 100 epoch(es)\n",
            "step 751 - loss 3.034417152404785 - moving ave loss 2.834122791153652\n",
            "step 752 - loss 2.646669864654541 - moving ave loss 2.815377498503741\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/flow\", line 7, in <module>\n",
            "    exec(compile(f.read(), __file__, 'exec'))\n",
            "  File \"/content/drive/My Drive/Colab Notebooks/YOLO-darkflow/darkflow/flow\", line 6, in <module>\n",
            "    cliHandler(sys.argv)\n",
            "  File \"/content/drive/My Drive/Colab Notebooks/YOLO-darkflow/darkflow/darkflow/cli.py\", line 33, in cliHandler\n",
            "    print('Enter training ...'); tfnet.train()\n",
            "  File \"/content/drive/My Drive/Colab Notebooks/YOLO-darkflow/darkflow/darkflow/net/flow.py\", line 39, in train\n",
            "    for i, (x_batch, datum) in enumerate(batches):\n",
            "  File \"/content/drive/My Drive/Colab Notebooks/YOLO-darkflow/darkflow/darkflow/net/yolo/data.py\", line 114, in shuffle\n",
            "    inp, new_feed = self._batch(train_instance)\n",
            "  File \"/content/drive/My Drive/Colab Notebooks/YOLO-darkflow/darkflow/darkflow/net/yolov2/data.py\", line 27, in _batch\n",
            "    img = self.preprocess(path, allobj)\n",
            "  File \"/content/drive/My Drive/Colab Notebooks/YOLO-darkflow/darkflow/darkflow/net/yolo/predict.py\", line 62, in preprocess\n",
            "    result = imcv2_affine_trans(im)\n",
            "  File \"/content/drive/My Drive/Colab Notebooks/YOLO-darkflow/darkflow/darkflow/utils/im_transform.py\", line 27, in imcv2_affine_trans\n",
            "    im = cv2.resize(im, (0,0), fx = scale, fy = scale)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Op6yYUPvTou2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c6dd682b-9334-4b6b-de3b-145ef8fa15ae"
      },
      "cell_type": "code",
      "source": [
        "# bin/tiny-yolo-voc.weights    initial weights\n",
        "!pwd"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/YOLO-darkflow/darkflow\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6xsBo7arTvJt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}